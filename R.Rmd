---
title: "TP1 TD VI"
author: "Dafydd Jenkins, Josefina Jahde y Serena Marelli"
date: "2025-03-20"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Introducción al problema



Nuestra eleccion sobre el dataset radica en que cumple con lo pedido, la cantidad de observaciones del conjunto de datos se encuentra en el rango que nos indicaron, tiene un numero razonable de features teniendo en cuenta que, según lo visto en la teórica, si hay una cantidad excesiva puede dar overfitting y nos parecio adecuado, modificando algunas variables a binario,  poder realizar el trabajo con esto.



## Preparación de los datos
```{r ej2, echo=FALSE}

datos <- read.csv('C:\\Users\\dafyd\\Documents\\Escuela\\2025\\semestre 1\\TD6\\TP1\\loan_data.csv', header=TRUE)
datos

```

Estadísticas descriptivas de las variables principales:
- person_age: 
```{r ej2, echo=FALSE}
datos_person_age<- datos$person_age
media_person_age <- mean(datos_person_age)
var_person_age <- var(datos_person_age)
sd_person_age <- sd(datos_person_age)

media_person_age
var_person_age
sd_person_age
```
- person_income:
```{r ej2, echo=FALSE}
datos_person_income<- datos$person_income
media_person_income <- mean(datos_person_income)
var_person_income <- var(datos_person_income)
sd_person_income <- sd(datos_person_income)

media_person_income
var_person_income
sd_person_income
```
- loan_amnt:
```{r ej2, echo=FALSE}
datos_loan_amnt<- datos$loan_amnt
media_loan_amnt <- mean(datos_loan_amnt)
var_loan_amnt <- var(datos_loan_amnt)
sd_loan_amnt <- sd(datos_loan_amnt)

media_loan_amnt
var_loan_amnt
sd_loan_amnt
```
-person_home_ownership:
```{r ej2, echo=FALSE}
library(ggplot2)
# Convertir a dataframe
datos_person_home_ownership <- data.frame(person_home_ownership = datos$person_home_ownership)

# Crear gráfico
ggplot(datos_person_home_ownership, aes(x = person_home_ownership)) + 
  geom_bar(fill = "blue") +
  labs(title = "Person home ownership ", x = "Cantidad", y = "Frecuencia") +
  theme_minimal()
```

-credit_score:
```{r ej2, echo=FALSE}
datos_credit_score<- datos$credit_score
media_credit_score <- mean(datos_credit_score)
var_credit_score <- var(datos_credit_score)
sd_credit_score <- sd(datos_credit_score)

media_credit_score
var_credit_score
sd_credit_score
```

-previous_loan_defaults_on_file:
```{r ej2, echo=FALSE}
datos_previous_loan_defaults_on_file<- datos$previous_loan_defaults_on_file
media_previous_loan_defaults_on_file <- mean(datos_previous_loan_defaults_on_file)
var_previous_loan_defaults_on_file <- var(datos_previous_loan_defaults_on_file)
sd_previous_loan_defaults_on_file <- sd(datos_previous_loan_defaults_on_file)

media_previous_loan_defaults_on_file
var_previous_loan_defaults_on_file
sd_previous_loan_defaults_on_file
```

- loan_status (la que se va a predecir):
```{r ej2, echo=FALSE}
datos_loan_status<- datos$loan_status
media_loan_status <- mean(datos_loan_status)
var_loan_status <- var(datos_loan_status)
sd_loan_status <- sd(datos_loan_status)

media_loan_status
var_loan_status
sd_loan_status
```

## Boxplots 
```{r ej2, echo=FALSE}
boxplot(list(person_income = datos_person_income, loan_amnt = datos_loan_amnt, credit_score = datos_credit_score, loan_status = datos_loan_status),
        col = c("red", "blue", "green","yellow", "purple"),
        main = "Boxplots de variables numéricas",
        xlab = "Variables",
        ylab = "Valores",
        ylim = c(0, 900000))
```

Luego de evaluar las estadísticas descriptivas y los boxplots de los parámetros que consideramos más relevantes, procedemos a realizar el preprocesamiento de datos.

```{r ej2, echo=FALSE}
datos$person_gender <- as.factor(datos$person_gender)
datos$person_education <- as.factor(datos$person_education)
datos$person_home_ownership <- as.factor(datos$person_home_ownership)
datos$loan_intent <- as.factor(datos$loan_intent)
datos$previous_loan_defaults_on_file <- as.factor(datos$previous_loan_defaults_on_file)
```

### 3
```{r ej3, echo=FALSE}
set.seed(678)
n <- nrow(datos)

# Índices aleatorios para cada subconjunto
train_idx <- sample(1:n, size = 0.7 * n)  # 70% para entrenamiento
temp_idx <- setdiff(1:n, train_idx)  # Restantes 30%

valid_idx <- sample(temp_idx, size = 0.5 * length(temp_idx))  # 15% validación
test_idx <- setdiff(temp_idx, valid_idx)  # 15% testeo

# Crear los conjuntos de datos
train <- datos[train_idx, ]
valid <- datos[valid_idx, ]
test <- datos[test_idx, ]
```

```{r ej3, echo=FALSE}
library(rpart)
library(rpart.plot)
```

```{r ej3, echo=FALSE}
base_tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
              data = train, 
              method = "class")
```

```{r ej3, echo=FALSE}
base_tree$control
rpart.plot(base_tree)
```

```{r ej4, echo=FALSE}
base_predictions_class  <- predict(base_tree, newdata = test, type = "class")
base_predictions_prob  <- predict(base_tree, newdata = test, type = "prob")
```

```{r ej4, echo=FALSE}
install.packages("MLmetrics")
```

```{r ej4, echo=FALSE}
#Accuracy
library(MLmetrics)
base_accuracy <- Accuracy(base_predictions_class, test$loan_status)
```

```{r ej4, echo=FALSE}
#Matriz de confusión
base_conf_matrix <- ConfusionMatrix(base_predictions_class, test$loan_status)
base_conf_matrix
```

```{r ej4, echo=FALSE}
#AUC
base_AUC <- AUC(base_predictions_class, test$loan_status)
base_AUC
```

```{r ej4, echo=FALSE}
#F1 Score
base_f1_score <- F1_Score(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_f1_score
```

```{r ej4, echo=FALSE}
#Precision
base_precision <- Precision(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_precision
```

```{r ej4, echo=FALSE}
#Recall
base_recall <- Recall(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_recall
```

```{r ej5, echo=FALSE}
AUCS <- c()
#paso <- 1
for (i in 1:20){
  matriz <- c()
  for (j in 1:20){
    vector <- c()
    for (k in 1:8){
      tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
              data = train, 
              method = "class",
              maxdepth = i,
              minsplit = j,
              minbucket = k,
              cp = 0,
              xval = 0)
      prediccion <- predict(tree, newdata = valid, type = "class")
      auc <- AUC(prediccion, valid$loan_status)
      vector <- append(vector, auc)
      #print(paso)
      #paso <- paso+1
    }
    matriz <- append(matriz, vector)
  }
  AUCS <- append(AUCS, matriz)
}
```

```{r ej5, echo=FALSE}
max(AUCS)
```

```{r ej5, echo=FALSE}
#install.packages("plotly")
library("plotly")
```

```{r ej5, echo=FALSE}
#GRAFICOS
```

```{r ej5, echo=FALSE}
# Encontrar la posición del valor máximo
max_pos <- which(AUCS == max(AUCS), arr.ind = TRUE)

# Imprimir el resultado
print(max_pos)
AUCS[2716]
3115/160
19*160
```
```{r ej5, echo=FALSE}
# Entrenamos el arbol con mejor AUC
tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
              data = train, 
              method = "class",
              maxdepth = 20,
              minsplit = 10,
              minbucket = 3,
              cp = 0,
              xval = 0)

# Predecimos sobre el conjunto de testeo
prediccion <- predict(tree, newdata = test, type = "class")
auc <- AUC(prediccion, test$loan_status)
auc
```
Vemos que con la grid search mejoramos la performance (medida con el AUC). Con el arbol base el AUC era 0.83 y con el optimizado 0.86.
