---
title: "TP1 TD VI"
author: "Dafydd Jenkins, Josefina Jahde y Serena Marelli"
date: "2025-03-20"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Introducción al problema



Nuestra eleccion sobre el dataset radica en que cumple con lo pedido, la cantidad de observaciones del conjunto de datos se encuentra en el rango que nos indicaron, tiene un numero razonable de features teniendo en cuenta que, según lo visto en la teórica, si hay una cantidad excesiva puede dar overfitting y nos parecio adecuado, modificando algunas variables a binario,  poder realizar el trabajo con esto.



## Preparación de los datos
```{r ej2, echo=FALSE}

#datos <- read.csv('C:\\Users\\dafyd\\Documents\\Escuela\\2025\\semestre 1\\TD6\\TP1\\loan_data.csv', header=TRUE)
datos <- read.csv('C:/Users/smare/OneDrive/Desktop/git/tp1td6/TD6_TP1/loan_data.csv', header=TRUE)
datos

```

Estadísticas descriptivas de las variables principales:
- person_age: 
```{r ej2, echo=FALSE}
datos_person_age<- datos$person_age
media_person_age <- mean(datos_person_age)
var_person_age <- var(datos_person_age)
sd_person_age <- sd(datos_person_age)

media_person_age
var_person_age
sd_person_age
```
- person_income:
```{r ej2, echo=FALSE}
datos_person_income<- datos$person_income
media_person_income <- mean(datos_person_income)
var_person_income <- var(datos_person_income)
sd_person_income <- sd(datos_person_income)

media_person_income
var_person_income
sd_person_income
```
- loan_amnt:
```{r ej2, echo=FALSE}
datos_loan_amnt<- datos$loan_amnt
media_loan_amnt <- mean(datos_loan_amnt)
var_loan_amnt <- var(datos_loan_amnt)
sd_loan_amnt <- sd(datos_loan_amnt)

media_loan_amnt
var_loan_amnt
sd_loan_amnt
```
-person_home_ownership:
```{r ej2, echo=FALSE}
library(ggplot2)
# Convertir a dataframe
datos_person_home_ownership <- data.frame(person_home_ownership = datos$person_home_ownership)

# Crear gráfico
ggplot(datos_person_home_ownership, aes(x = person_home_ownership)) + 
  geom_bar(fill = "blue") +
  labs(title = "Person home ownership ", x = "Cantidad", y = "Frecuencia") +
  theme_minimal()
```

-credit_score:
```{r ej2, echo=FALSE}
datos_credit_score<- datos$credit_score
media_credit_score <- mean(datos_credit_score)
var_credit_score <- var(datos_credit_score)
sd_credit_score <- sd(datos_credit_score)

media_credit_score
var_credit_score
sd_credit_score
```

-previous_loan_defaults_on_file:
```{r ej2, echo=FALSE}
datos_previous_loan_defaults_on_file<- datos$previous_loan_defaults_on_file
media_previous_loan_defaults_on_file <- mean(datos_previous_loan_defaults_on_file)
var_previous_loan_defaults_on_file <- var(datos_previous_loan_defaults_on_file)
sd_previous_loan_defaults_on_file <- sd(datos_previous_loan_defaults_on_file)

media_previous_loan_defaults_on_file
var_previous_loan_defaults_on_file
sd_previous_loan_defaults_on_file
```

- loan_status (la que se va a predecir):
```{r ej2, echo=FALSE}
datos_loan_status<- datos$loan_status
media_loan_status <- mean(datos_loan_status)
var_loan_status <- var(datos_loan_status)
sd_loan_status <- sd(datos_loan_status)

media_loan_status
var_loan_status
sd_loan_status
```

## Boxplots 
```{r ej2, echo=FALSE}
boxplot(list(person_income = datos_person_income, loan_amnt = datos_loan_amnt, credit_score = datos_credit_score, loan_status = datos_loan_status),
        col = c("red", "blue", "green","yellow", "purple"),
        main = "Boxplots de variables numéricas",
        xlab = "Variables",
        ylab = "Valores",
        ylim = c(0, 900000))
```

Luego de evaluar las estadísticas descriptivas y los boxplots de los parámetros que consideramos más relevantes, procedemos a realizar el preprocesamiento de datos.

```{r ej2, echo=FALSE}
datos$person_gender <- as.factor(datos$person_gender)
datos$person_education <- as.factor(datos$person_education)
datos$person_home_ownership <- as.factor(datos$person_home_ownership)
datos$loan_intent <- as.factor(datos$loan_intent)
datos$previous_loan_defaults_on_file <- as.factor(datos$previous_loan_defaults_on_file)
```

### 3
```{r ej3, echo=FALSE}
set.seed(678)
n <- nrow(datos)

# Índices aleatorios para cada subconjunto
train_idx <- sample(1:n, size = 0.7 * n)  # 70% para entrenamiento
temp_idx <- setdiff(1:n, train_idx)  # Restantes 30%

valid_idx <- sample(temp_idx, size = 0.5 * length(temp_idx))  # 15% validación
test_idx <- setdiff(temp_idx, valid_idx)  # 15% testeo

# Crear los conjuntos de datos
train <- datos[train_idx, ]
valid <- datos[valid_idx, ]
test <- datos[test_idx, ]
```

```{r ej3, echo=FALSE}
library(rpart)
library(rpart.plot)
```

```{r ej3, echo=FALSE}
base_tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
              data = train, 
              method = "class")
```

```{r ej3, echo=FALSE}
base_tree$control
rpart.plot(base_tree)
```

```{r ej4, echo=FALSE}
base_predictions_class  <- predict(base_tree, newdata = test, type = "class")
base_predictions_prob  <- predict(base_tree, newdata = test, type = "prob")
```

```{r ej4, echo=FALSE}
install.packages("MLmetrics")
```

```{r ej4, echo=FALSE}
#Accuracy
library(MLmetrics)
base_accuracy <- Accuracy(base_predictions_class, test$loan_status)
```

```{r ej4, echo=FALSE}
#Matriz de confusión
base_conf_matrix <- ConfusionMatrix(base_predictions_class, test$loan_status)
base_conf_matrix
```

```{r ej4, echo=FALSE}
#AUC
base_AUC <- AUC(base_predictions_class, test$loan_status)
base_AUC
```

```{r ej4, echo=FALSE}
#F1 Score
base_f1_score <- F1_Score(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_f1_score
```

```{r ej4, echo=FALSE}
#Precision
base_precision <- Precision(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_precision
```

```{r ej4, echo=FALSE}
#Recall
base_recall <- Recall(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_recall
```

## 5. Optimización del modelo

Para experimentar con distintas combinaciones de maxdepth, minsplit y minbucket, creamos la función gridSearch. Esta recibe como parámetros los conjuntos de training y validation de un dataframe, y los valores máximos de maxdepth, minsplit y minbucket que vamos a probar. Nuestro objetivo es hallar la combinación de hiperparámetros que nos dan el árbol con mayor AUC-ROC.

```{r ej5, echo=FALSE}
gridSearch <- function(df_train, df_valid, maxdepth_hasta, minsplit_hasta, minbucket_hasta) {
    maxd = 1
    mins = 1
    minb = 1
    mejor_auc = 0
    for (i in 1:maxdepth_hasta){
      for (j in 1:minsplit_hasta){
        for (k in 1:minbucket_hasta){
          tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
                data = df_train, 
                method = "class",
                maxdepth = i,
                minsplit = j,
                minbucket = k,
                cp = 0,
                xval = 0)
          prediccion <- predict(tree, newdata = df_valid, type = "class")
          auc <- AUC(prediccion, df_valid$loan_status)
          # Si el árbol actual tiene el AUC más alto hasta ahora, guardo los valores de los hiperparámetros
          if (auc > mejor_auc){
            maxd <- i
            mins <- j
            minb <- k
            mejor_auc <- auc
          }
        }
      }
    }
  return(c(mejor_auc,maxd,mins,minb))
  }
```

```{r ej5, echo=FALSE}
mejor_arbol <- gridSearch(train,valid,20,20,8)
mej_auc = mejor_arbol[0]
mej_maxd = mejor_arbol[1]
mej_mins = mejor_arbol[2]
mej_minb = mejor_arbol[3]
```

```{r ej5, echo=FALSE}
# Entrenamos el arbol con mejor AUC
tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
              data = train, 
              method = "class",
              maxdepth = mej_maxd,
              minsplit = mej_mins,
              minbucket = mej_minb,
              cp = 0,
              xval = 0)

# Predecimos sobre el conjunto de testeo
prediccion <- predict(tree, newdata = test, type = "class")
auc <- AUC(prediccion, test$loan_status)
auc
```
Vemos que con la grid search mejoramos la performance (medida con el AUC). Con el arbol base el AUC era 0.83 y con el optimizado 0.86.,

```{r ej5, echo=FALSE}
#install.packages("plotly")
library("plotly")
```

```{r ej5, echo=FALSE}
#GRAFICOS
```

## 6. Interpretación de resultados (10 puntos)


## 7. Análisis del impacto de los valores faltantes

```{r ej7, echo=FALSE}
datos_20 <- datos # 20% missings
datos_50 <- datos # 50% missings
datos_75 <- datos # 75% missings

for (col in colnames(datos_20)) {
  cant_missings <- round(nrow(datos_20) * 0.2)
  na_positions <- sample(nrow(datos_20), cant_missings, replace = FALSE)
  datos_20[na_positions, col] <- NA  
}

for (col in colnames(datos_50)) {
  cant_missings <- round(nrow(datos_50) * 0.5)
  na_positions <- sample(nrow(datos_50), cant_missings, replace = FALSE)
  datos_50[na_positions, col] <- NA  
}

for (col in colnames(datos_75)) {
  cant_missings <- round(nrow(datos_75) * 0.75)
  na_positions <- sample(nrow(datos_75), cant_missings, replace = FALSE)
  datos_75[na_positions, col] <- NA  
}

#print(colSums(is.na(datos_20)))
#print(colSums(is.na(datos_50)))
#print(colSums(is.na(datos_75)))

```

Creamos los conjuntos de train, validation y test para los 3 sets nuevos y hacemos grid search para cada uno
```{r ej7, echo=FALSE}
# Set 20% missings
train_20 <- datos_20[train_idx, ]
valid_20 <- datos_20[valid_idx, ]
test_20 <- datos_20[test_idx, ]

mejor_arbol_20 <- gridSearch(train_20,valid_20,20,20,8)
mej_auc_20 = mejor_arbol_20[0]
mej_maxd_20 = mejor_arbol_20[1]
mej_mins_20 = mejor_arbol_20[2]
mej_minb_20 = mejor_arbol_20[3]
```

```{r ej7, echo=FALSE}
# Set 50% missings
train_50 <- datos_50[train_idx, ]
valid_50 <- datos_50[valid_idx, ]
test_50 <- datos_50[test_idx, ]

mejor_arbol_50 <- gridSearch(train_50,valid_50,20,20,8)
mej_auc_50 = mejor_arbol_50[0]
mej_maxd_50 = mejor_arbol_50[1]
mej_mins_50 = mejor_arbol_50[2]
mej_minb_50 = mejor_arbol_50[3]
```

```{r ej7, echo=FALSE}
# Set 75% missings
train_75 <- datos_75[train_idx, ]
valid_75 <- datos_75[valid_idx, ]
test_75 <- datos_75[test_idx, ]

mejor_arbol_75 <- gridSearch(train_75,valid_75,20,20,8)
mej_auc_75 = mejor_arbol_75[0]
mej_maxd_75 = mejor_arbol_75[1]
mej_mins_75 = mejor_arbol_75[2]
mej_minb_75 = mejor_arbol_75[3]
```

























```
