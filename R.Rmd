---
title: "TP1 TD VI"
author: "Dafydd Jenkins, Josefina Jahde y Serena Marelli"
date: "2025-03-20"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Introducción al problema



Nuestra eleccion sobre el dataset radica en que cumple con lo pedido, la cantidad de observaciones del conjunto de datos se encuentra en el rango que nos indicaron, tiene un numero razonable de features teniendo en cuenta que, según lo visto en la teórica, si hay una cantidad excesiva puede dar overfitting y nos parecio adecuado, modificando algunas variables a binario,  poder realizar el trabajo con esto.



## Preparación de los datos
```{r ej2, echo=FALSE}

datos <- read.csv('C:\\Users\\dafyd\\Documents\\Escuela\\2025\\semestre 1\\TD6\\TP1\\loan_data.csv', header=TRUE)
#datos <- read.csv('C:/Users/smare/OneDrive/Desktop/git/tp1td6/TD6_TP1/loan_data.csv', header=TRUE)
datos

```

Estadísticas descriptivas de las variables principales:
- person_age: 
```{r ej2, echo=FALSE}
datos_person_age<- datos$person_age
mean(datos_person_age)
var(datos_person_age)
sd(datos_person_age)
boxplot(datos_person_age)
```
- person_income:
```{r ej2, echo=FALSE}
datos_person_income<- datos$person_income
mean(datos_person_income)
var(datos_person_income)
sd(datos_person_income)
boxplot(datos_person_income)

```
- loan_amnt:
```{r ej2, echo=FALSE}
datos_loan_amnt<- datos$loan_amnt
mean(datos_loan_amnt)
var(datos_loan_amnt)
sd(datos_loan_amnt)
boxplot(datos_loan_amnt)
```
-person_home_ownership:
```{r ej2, echo=FALSE}
library(ggplot2)
# Convertir a dataframe
datos_person_home_ownership <- data.frame(person_home_ownership = datos$person_home_ownership)

# Crear gráfico
ggplot(datos_person_home_ownership, aes(x = person_home_ownership)) + 
  geom_bar(fill = "blue") +
  labs(title = "Person home ownership ", x = "Cantidad", y = "Frecuencia") +
  theme_minimal()
```

-credit_score:
```{r ej2, echo=FALSE}
datos_credit_score<- datos$credit_score
mean(datos_credit_score)
var(datos_credit_score)
sd(datos_credit_score)
boxplot(datos_credit_score)
```

-previous_loan_defaults_on_file:
```{r ej2, echo=FALSE}
datos_previous_loan_defaults_on_file<- datos$previous_loan_defaults_on_file
cant_si <- 0
for (i in 1:nrow(datos)){
  if (datos_previous_loan_defaults_on_file[i] == 'Yes'){
    cant_si <- cant_si + 1
  }
}

df <- data.frame(
  categoria = c("has defaulted", "Never defaulted"),
  valores = c(cant_si, nrow(datos)-cant_si)
)

df$porcentaje <- round(df$valores / sum(df$valores) * 100, 1)
df$etiquetas <- paste0(df$porcentaje, "%")  # Formato de etiqueta

ggplot(df, aes(x = "", y = valores, fill = categoria)) +
  geom_bar(stat = "identity", width = 1) +  # Crear la torta
  coord_polar("y") +  # Convertir a torta
  geom_text(aes(label = etiquetas), position = position_stack(vjust = 0.5), size = 5) +  # Agregar % en el centro de cada porción
  theme_void() +  # Quitar ejes
  labs(title = "Proporción de Defaults")

```

- loan_status (la que se va a predecir):
```{r ej2, echo=FALSE}
datos_loan_status<- datos$loan_status
media_loan_status <- mean(datos_loan_status)
var_loan_status <- var(datos_loan_status)
sd_loan_status <- sd(datos_loan_status)

media_loan_status
var_loan_status
sd_loan_status

```

Luego de evaluar las estadísticas descriptivas y los boxplots de los parámetros que consideramos más relevantes, procedemos a realizar el preprocesamiento de datos.

```{r ej2, echo=FALSE}
datos$person_gender <- as.factor(datos$person_gender)
datos$person_education <- as.factor(datos$person_education)
datos$person_home_ownership <- as.factor(datos$person_home_ownership)
datos$loan_intent <- as.factor(datos$loan_intent)
datos$previous_loan_defaults_on_file <- as.factor(datos$previous_loan_defaults_on_file)
```

### 3
```{r ej3, echo=FALSE}
set.seed(678)
n <- nrow(datos)

# Índices aleatorios para cada subconjunto
train_idx <- sample(1:n, size = 0.7 * n)  # 70% para entrenamiento
temp_idx <- setdiff(1:n, train_idx)  # Restantes 30%

valid_idx <- sample(temp_idx, size = 0.5 * length(temp_idx))  # 15% validación
test_idx <- setdiff(temp_idx, valid_idx)  # 15% testeo

# Crear los conjuntos de datos
train <- datos[train_idx, ]
valid <- datos[valid_idx, ]
test <- datos[test_idx, ]
```

```{r ej3, echo=FALSE}
library(rpart)
library(rpart.plot)
```

```{r ej3, echo=FALSE}
base_tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
              data = train, 
              method = "class")
```

```{r ej3, echo=FALSE}
base_tree$control
rpart.plot(base_tree)
```

```{r ej4, echo=FALSE}
base_predictions_class  <- predict(base_tree, newdata = test, type = "class")
base_predictions_prob  <- predict(base_tree, newdata = test, type = "prob")
```

```{r ej4, echo=FALSE}
#install.packages("MLmetrics")
```

```{r ej4, echo=FALSE}
#Accuracy
library(MLmetrics)
base_accuracy <- Accuracy(base_predictions_class, test$loan_status)
```

```{r ej4, echo=FALSE}
#Matriz de confusión
base_conf_matrix <- ConfusionMatrix(base_predictions_class, test$loan_status)
base_conf_matrix
```

```{r ej4, echo=FALSE}
#AUC
base_AUC <- AUC(base_predictions_class, test$loan_status)
base_AUC
```

```{r ej4, echo=FALSE}
#F1 Score
base_f1_score <- F1_Score(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_f1_score
```

```{r ej4, echo=FALSE}
#Precision
base_precision <- Precision(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_precision
```

```{r ej4, echo=FALSE}
#Recall
base_recall <- Recall(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_recall
```

## 5. Optimización del modelo

Para experimentar con distintas combinaciones de maxdepth, minsplit y minbucket, creamos la función gridSearch. Esta recibe como parámetros los conjuntos de training y validation de un dataframe, y los valores máximos de maxdepth, minsplit y minbucket que vamos a probar. Nuestro objetivo es hallar la combinación de hiperparámetros que nos dan el árbol con mayor AUC-ROC.

```{r ej5, echo=FALSE}
train_tree_with_hyperparameters <- function(train_data, max_depth, min_split, min_bucket){
  tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
                data = train_data, 
                method = "class",
                maxdepth = max_depth,
                minsplit = min_split,
                minbucket = min_bucket,
                cp = 0,
                xval = 0)
  return (tree)
}

gridSearch <- function(df_train, df_valid, maxdepth_hasta, minsplit_hasta, minbucket_hasta) {
    maxd = 1
    mins = 1
    minb = 1
    mejor_auc = 0
    for (i in 1:maxdepth_hasta){
      for (j in 1:minsplit_hasta){
        for (k in 1:minbucket_hasta){
          tree <- train_tree_with_hyperparameters(df_train, i, j, k)
          #rpart.plot(tree)
          prediccion <- predict(tree, newdata = df_valid, type = "class")
          auc <- AUC(prediccion, df_valid$loan_status)
          print(auc)
          # Si el árbol actual tiene el AUC más alto hasta ahora, guardo los valores de los hiperparámetros
          if (!is.na(auc) && auc > mejor_auc){
            maxd <- i
            mins <- j
            minb <- k
            mejor_auc <- auc
          }
        }
      }
    }
  return(c(mejor_auc,maxd,mins,minb))
}

```

```{r ej5, echo=FALSE}
mejor_arbol <- gridSearch(train,valid,20,20,8)

```

```{r ej5, echo=FALSE}
mej_auc = mejor_arbol[1]
mej_maxd = mejor_arbol[2]
mej_mins = mejor_arbol[3]
mej_minb = mejor_arbol[4]
```

```{r ej5, echo=FALSE}
# Entrenamos el arbol con mejor AUC
tree <- train_tree_with_hyperparameters(train, mej_maxd, mej_mins, mej_minb)

# Predecimos sobre el conjunto de testeo
prediccion <- predict(tree, newdata = test, type = "class")
auc <- AUC(prediccion, test$loan_status)
auc
```
Vemos que con la grid search mejoramos la performance (medida con el AUC). Con el arbol base el AUC era 0.83 y con el optimizado 0.86.,

```{r ej5, echo=FALSE}
#install.packages("plotly")
library("plotly")
```

```{r ej5, echo=FALSE}
#GRAFICOS
```

## 6. Interpretación de resultados (10 puntos)


## 7. Análisis del impacto de los valores faltantes

```{r ej7, echo=FALSE}
datos_20 <- datos # 20% missings
datos_50 <- datos # 50% missings
datos_75 <- datos # 75% missings

for (col in colnames(datos_20)) {
  cant_missings <- round(nrow(datos_20) * 0.2)
  na_positions <- sample(nrow(datos_20), cant_missings, replace = FALSE)
  datos_20[na_positions, col] <- NA  
}

for (col in colnames(datos_50)) {
  cant_missings <- round(nrow(datos_50) * 0.5)
  na_positions <- sample(nrow(datos_50), cant_missings, replace = FALSE)
  datos_50[na_positions, col] <- NA  
}

for (col in colnames(datos_75)) {
  cant_missings <- round(nrow(datos_75) * 0.75)
  na_positions <- sample(nrow(datos_75), cant_missings, replace = FALSE)
  datos_75[na_positions, col] <- NA  
}

#print(colSums(is.na(datos_20)))
#print(colSums(is.na(datos_50)))
#print(colSums(is.na(datos_75)))

```

Creamos los conjuntos de train, validation y test para los 3 sets nuevos y hacemos grid search para cada uno
```{r ej7, echo=FALSE}
# Set 20% missings
train_20 <- datos_20[train_idx, ]
valid_20 <- datos_20[valid_idx, ]
test_20 <- datos_20[test_idx, ]

mejor_arbol_20 <- gridSearch(train_20,valid_20,20,20,8)
mej_auc_20 = mejor_arbol_20[1]
mej_maxd_20 = mejor_arbol_20[2]
mej_mins_20 = mejor_arbol_20[3]
mej_minb_20 = mejor_arbol_20[4]
```

```{r ej7, echo=FALSE}
# Set 50% missings
train_50 <- datos_50[train_idx, ]
valid_50 <- datos_50[valid_idx, ]
test_50 <- datos_50[test_idx, ]

mejor_arbol_50 <- gridSearch(train_50,valid_50,20,20,8)
mej_auc_50 = mejor_arbol_50[0]
mej_maxd_50 = mejor_arbol_50[1]
mej_mins_50 = mejor_arbol_50[2]
mej_minb_50 = mejor_arbol_50[3]
```

```{r ej7, echo=FALSE}
# Set 75% missings
train_75 <- datos_75[train_idx, ]
valid_75 <- datos_75[valid_idx, ]
test_75 <- datos_75[test_idx, ]

mejor_arbol_75 <- gridSearch(train_75,valid_75,20,20,8)
mej_auc_75 = mejor_arbol_75[0]
mej_maxd_75 = mejor_arbol_75[1]
mej_mins_75 = mejor_arbol_75[2]
mej_minb_75 = mejor_arbol_75[3]
```

























```
