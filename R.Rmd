---
title: "TP1 TD VI"
author: "Dafydd Jenkins, Josefina Jahde y Serena Marelli"
date: "2025-03-20"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##Introducción al problema

El presente trabajo aborda el problema de clasificación en la aprobación de préstamos utilizando el conjunto de datos Loan Approval Classification Data, disponible en Kaggle. Este dataset contiene información relevante sobre solicitudes de préstamo, incluyendo variables clave como historial crediticio, ingresos del solicitante, monto del préstamo, estado civil y nivel educativo, entre otras. El objetivo principal es predecir si una solicitud de préstamo será aprobada o rechazada en función de estos atributos.

La elección de este conjunto de datos para la aplicación de árboles de decisión se justifica por varias razones. En primer lugar, el problema es de naturaleza discreta y estructurada, lo que facilita la segmentación y análisis de las características mediante divisiones sucesivas. Además, los árboles de decisión ofrecen interpretabilidad, permitiendo entender cómo cada variable influye en la decisión final. Finalmente, el dataset contiene una combinación de variables categóricas y numéricas, lo que permite evaluar la capacidad de los árboles de decisión para manejar distintos tipos de datos y generar reglas claras para la clasificación.

Consideramos que las variables principalmente influyentes a la hora de predecir serán:
- Person age: mayor edad puede asociarse a mayor solvencia económica o estabilidad financiera.
- Person income: resulta natural que a mayor ingresos, más probabilidades hay de obtener un préstamo.
- Loan amount: este parámetro en relación al Person Income, debería ayudar a definir la obtención o no del préstamo.
- Person Home Ownership: este dato suele ser muy considerado en Estados Unidos (lugar de orgien del autor del dataset)
- Credit Score: esta es otra medida que indica la solvencia financiera de una persona. Se usa para evaluar el riesgo de otorgar un préstamo o crédito, indicando la probabilidad de que el solicitante pague a tiempo sus deudas.
- Previous Loan Defaults on File: debería resultar relevante saber si el solicitante ya ha fallado en pagar deudas de préstamos en el pasado.

## Preparación de los datos
```{r , echo=FALSE}

datos <- read.csv('C:\\Users\\dafyd\\Documents\\Escuela\\2025\\semestre 1\\TD6\\TP1\\loan_data.csv', header=TRUE)
#datos <- read.csv('C:/Users/smare/OneDrive/Desktop/git/tp1td6/TD6_TP1/loan_data.csv', header=TRUE)
datos

```

Estadísticas descriptivas de las variables principales:
- person_age:
A continuación se presentan edad promedio de los solicitantes, varianza y desvío estándar:
```{r, echo=FALSE}
datos_person_age<- datos$person_age
mean(datos_person_age)
var(datos_person_age)
sd(datos_person_age)
boxplot(datos_person_age)
```
Con el boxplot se puede ver que hay algunos outliers extraños de 140 años. Creemos que se debe a errores al cargar los datos. De todas formas, como son 5 casos de los 45000 totales, decidimos que no debería representar grandes problemas.

- person_income:
A continuación se presentan ingresos promedio de los solicitantes, varianza y desvío estándar:
```{r, echo=FALSE}
datos_person_income<- datos$person_income
mean(datos_person_income)
var(datos_person_income)
sd(datos_person_income)
boxplot(datos_person_income)

```
- loan_amnt:
A continuación se presentan monto pedido promedio de los solicitantes, varianza y desvío estándar:
```{r , echo=FALSE}
datos_loan_amnt<- datos$loan_amnt
mean(datos_loan_amnt)
var(datos_loan_amnt)
sd(datos_loan_amnt)
boxplot(datos_loan_amnt)
```
-person_home_ownership:
A continuación se muestra la cantidad de casos para cada categoría de esta variable:
```{r , echo=FALSE}
library(ggplot2)
# Convertir a dataframe
datos_person_home_ownership <- data.frame(person_home_ownership = datos$person_home_ownership)

# Crear gráfico
ggplot(datos_person_home_ownership, aes(x = person_home_ownership)) + 
  geom_bar(fill = "blue") +
  labs(title = "Person home ownership ", x = "Cantidad", y = "Frecuencia") +
  theme_minimal()
```

-credit_score:
A continuación se presenta el puntaje crediticio promedio de los solicitantes, varianza y desvío estándar:
```{r , echo=FALSE}
datos_credit_score<- datos$credit_score
mean(datos_credit_score)
var(datos_credit_score)
sd(datos_credit_score)
boxplot(datos_credit_score)
```

-previous_loan_defaults_on_file:
Se presenta un gráfico con la proporción de solicitantes que han fallado en pagar sus préstamos en el pasado.
```{r , echo=FALSE}
datos_previous_loan_defaults_on_file<- datos$previous_loan_defaults_on_file
cant_si <- 0
for (i in 1:nrow(datos)){
  if (datos_previous_loan_defaults_on_file[i] == 'Yes'){
    cant_si <- cant_si + 1
  }
}

df <- data.frame(
  categoria = c("has defaulted", "Never defaulted"),
  valores = c(cant_si, nrow(datos)-cant_si)
)

df$porcentaje <- round(df$valores / sum(df$valores) * 100, 1)
df$etiquetas <- paste0(df$porcentaje, "%")  # Formato de etiqueta

ggplot(df, aes(x = "", y = valores, fill = categoria)) +
  geom_bar(stat = "identity", width = 1) +  # Crear la torta
  coord_polar("y") +  # Convertir a torta
  geom_text(aes(label = etiquetas), position = position_stack(vjust = 0.5), size = 5) +  # Agregar % en el centro de cada porción
  theme_void() +  # Quitar ejes
  labs(title = "Proporción de Defaults")

```

- loan_status (la que se va a predecir):
A continuación se presenta la proporción de préstamos otorgados
```{r , echo=FALSE}
datos_loan_status<- datos$loan_status
media_loan_status <- mean(datos_loan_status)
var_loan_status <- var(datos_loan_status)
sd_loan_status <- sd(datos_loan_status)

media_loan_status
```

Luego de evaluar las estadísticas descriptivas y los boxplots de los parámetros que consideramos más relevantes, procedemos a realizar el preprocesamiento de datos.

```{r , echo=FALSE}
datos$person_gender <- as.factor(datos$person_gender)
datos$person_education <- as.factor(datos$person_education)
datos$person_home_ownership <- as.factor(datos$person_home_ownership)
datos$loan_intent <- as.factor(datos$loan_intent)
datos$previous_loan_defaults_on_file <- as.factor(datos$previous_loan_defaults_on_file)
```

## 3. Construcción de un árbol de decisión básico

```{r , echo=FALSE}
set.seed(678)
n <- nrow(datos)

# Índices aleatorios para cada subconjunto
train_idx <- sample(1:n, size = 0.7 * n)  # 70% para entrenamiento
temp_idx <- setdiff(1:n, train_idx)  # Restantes 30%

valid_idx <- sample(temp_idx, size = 0.5 * length(temp_idx))  # 15% validación
test_idx <- setdiff(temp_idx, valid_idx)  # 15% testeo

# Crear los conjuntos de datos
train <- datos[train_idx, ]
valid <- datos[valid_idx, ]
test <- datos[test_idx, ]
```

```{r , echo=FALSE}
library(rpart)
library(rpart.plot)
```

```{r , echo=FALSE}
base_tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
              data = train, 
              method = "class")
```

```{r , echo=FALSE}
base_tree$control
rpart.plot(base_tree)
base_tree$variable.importance
```
## 4. Evaluación del árbol de decisión básico

```{r , echo=FALSE}
base_predictions_class  <- predict(base_tree, newdata = test, type = "class")
base_predictions_prob  <- predict(base_tree, newdata = test, type = "prob")
```

```{r , echo=FALSE}
#install.packages("MLmetrics")
```

```{r , echo=FALSE}
#Accuracy
library(MLmetrics)
base_accuracy <- Accuracy(base_predictions_class, test$loan_status)
```

```{r , echo=FALSE}
#Matriz de confusión
base_conf_matrix <- ConfusionMatrix(base_predictions_class, test$loan_status)
base_conf_matrix
```

```{r , echo=FALSE}
#AUC
base_AUC <- AUC(base_predictions_class, test$loan_status)
base_AUC
```

```{r , echo=FALSE}
#F1 Score
base_f1_score <- F1_Score(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_f1_score
```

```{r , echo=FALSE}
#Precision
base_precision <- Precision(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_precision
```

```{r , echo=FALSE}
#Recall
base_recall <- Recall(base_predictions_class, test$loan_status, positive='1') # PREGUNTARRRR
base_recall
```

- Accuracy: Esta metrica nos dio como resultado  0.9117168, lo que significa que el modelo clasifica correctamente el 91.17% de los casos en el conjunto de prueba.

- Precision: De los que dijimos que eran positivos,  72,2% son efectivamente positivos.

- recall: De los que efectivamente son positivos, el 83,5% dijimos que eran positivos.

- F1-score: Esta metrica nos dió como resultado 0,7745  modelo tiene un buen balance entre precisión y recall, aunque no es perfecto.

- AUC-ROC: Nos dio  0.8423256, lo que significa que el modelo tiene buena  capacidad de clasificacion, esta arriba de un modelo aleatorio.

- Matriz de confusión:La matriz indica que el modelo clasificó correctamente 5069 casos negativos, es decir, donde la clase real era 0 y el modelo también predijo 0. 
Hay 210 casos en los que el modelo predijo 1 (positivo), pero en realidad la clase era 0.
El modelo falló en 409 casos donde la clase real era 1, pero predijo 0. Hay algunos casos positivos que no fueron detectados correctamente.
finalmente, en 1063 casos el modelo detectó correctamente la clase positiva.

## 5. Optimización del modelo

Para experimentar con distintas combinaciones de maxdepth, minsplit y minbucket, creamos la función gridSearch. Esta recibe como parámetros los conjuntos de training y validation de un dataframe, y los valores máximos de maxdepth, minsplit y minbucket que vamos a probar. Nuestro objetivo es hallar la combinación de hiperparámetros que nos dan el árbol con mayor AUC-ROC.

```{r , echo=FALSE}
train_tree_with_hyperparameters <- function(train_data, max_depth, min_split, min_bucket){
  tree <- rpart(formula = loan_status ~ person_age + person_gender + person_education + person_income + person_emp_exp + person_home_ownership + loan_amnt + loan_intent + loan_int_rate + loan_percent_income + cb_person_cred_hist_length + credit_score + previous_loan_defaults_on_file, 
                data = train_data, 
                method = "class",
                maxdepth = max_depth,
                minsplit = min_split,
                minbucket = min_bucket,
                cp = 0,
                xval = 0)
  return (tree)
}

gridSearch <- function(df_train, df_valid, maxdepth_hasta, minsplit_hasta, minbucket_hasta) {
    maxd = 1
    mins = 1
    minb = 1
    mejor_auc = 0
    AUCS <- c()
    for (i in 1:maxdepth_hasta){
      #print(i)
      for (j in 1:minsplit_hasta){
        for (k in 1:minbucket_hasta){
          tree <- train_tree_with_hyperparameters(df_train, i, j, k)
          #rpart.plot(tree)
          prediccion <- predict(tree, newdata = df_valid, type = "class")
          auc <- AUC(prediccion, df_valid$loan_status)
          #print(auc)
          # Si el árbol actual tiene el AUC más alto hasta ahora, guardo los valores de los hiperparámetros
          if (!is.na(auc) && auc > mejor_auc){
            maxd <- i
            mins <- j
            minb <- k
            mejor_auc <- auc
          }
          # Guardar el AUC en un vector para graficar
          AUCS <- c(AUCS, auc)
        }
      }
    }
  return(c(mejor_auc,maxd,mins,minb, AUCS))
}

```

```{r , echo=FALSE}
resultados <- gridSearch(train,valid,20,20,8)
mejor_auc <- resultados[1]
mejor_maxd <- resultados[2]
mejor_mins <- resultados[3]
mejor_minb <- resultados[4]
aucs_calculados <- resultados[5:length(resultados)]
#aucs_calculados
```

```{r , echo=FALSE}
#maxdepth
x_maxD <- c()
for (i in 1:20){
  for (j in 1:160){
    x_maxD <- c(x_maxD, i)
  }
}
```

```{r , echo=FALSE}
# Gráfico de dispersión
plot(x_maxD, aucs_calculados, 
     main = "AUc según max_depth", 
     xlab = "max_depth", 
     ylab = "AUC", 
     col = "blue", 
     pch = 19)  # pch define el tipo de punto
```

```{r , echo=FALSE}
#minsplit
x_minS <- c()
for (i in 1:20){
  for (j in 1:20){
    for (k in 1:8){
      x_minS <- c(x_minS, j)
    }
  }
}
```

```{r , echo=FALSE}
# Gráfico de dispersión
plot(x_minS, aucs_calculados, 
     main = "AUc según minsplit", 
     xlab = "minsplit", 
     ylab = "AUC", 
     col = "red", 
     pch = 19)  # pch define el tipo de punto
```

```{r , echo=FALSE}
#minbucket
x_minB <- c()
for (i in 1:160){
  for (j in 1:20){
    x_minB <- c(x_minB, j)
  }
}
```
```{r , echo=FALSE}
# Gráfico de dispersión
plot(x_minB, aucs_calculados, 
     main = "AUc según minbucket", 
     xlab = "minbucket", 
     ylab = "AUC", 
     col = "green", 
     pch = 19)  # pch define el tipo de punto
```

```{r , echo=FALSE}
# Entrenamos el arbol con mejor AUC
best_tree <- train_tree_with_hyperparameters(train, mej_maxd, mej_mins, mej_minb)

# Predecimos sobre el conjunto de testeo
prediccion <- predict(best_tree, newdata = test, type = "class")
auc <- AUC(prediccion, test$loan_status)
auc
```
Vemos que con la grid search mejoramos la performance (medida con el AUC). Con el arbol base el AUC era 0.83 y con el optimizado 0.86.

## 6. Interpretación de resultados (10 puntos)
Se presenta el arbol final optimizado
```{r , echo=FALSE}
best_tree$control
rpart.plot(best_tree, roundint = FALSE)
```
Como se puede ver, el arbol optimizado es mucho más profundo y con más nodos finales. Esto nos dice que probablemente haya overfitting con respecto al arbol entrenado en el ejercicio 3. Sin embargo, como vimos en el 
ejercicio 5, el AUC sobre el conjunto de test también es mayor que el del arbol base, por lo l amayor flexibilidad del arbol no necesariamente tendría que ser un problema.

Para identificar los nodos superiores del arbol, lo volvemos a graficar, pero solo hasta el nivel 5.

```{r , echo=FALSE}
best_tree$cptable

# Podar el árbol con el valor de cp
pruned_tree <- prune(best_tree, cp = 2.581330e-03)

# Graficar el árbol podado
rpart.plot(pruned_tree)

best_tree$variable.importance
```

Como podemos ver, los primeros niveles del arbol se mantuvieron iguales que en el arbol base. Las variables más importantes no cambiaron. Esto nos indica que cambiar los hiperparámetros no llevó a cambios en la jerarquía de importancia dada a cada variable. Sin emabrgo, procedemos a hacer un análisis más exhaustivo con rpart para obtener la importancia de cada parametro real.

```{r , echo=FALSE}
print("Importancia de parámetros para el arbol base")
base_tree$variable.importance
print("Importancia de parámetros para el mejor arbol")
best_tree$variable.importance
```
Como vemos, si hay cambios en los valores numéricos de la importancia de cada variable. Además, vemos que a partir de loan_intent comienzan a haber cambios en la jerarquía de importancia de las variables.
## 7. Análisis del impacto de los valores faltantes

```{r , echo=FALSE}
datos_20 <- datos # 20% missings
datos_50 <- datos # 50% missings
datos_75 <- datos # 75% missings

for (col in colnames(datos_20)) {
  cant_missings <- round(nrow(datos_20) * 0.2)
  na_positions <- sample(nrow(datos_20), cant_missings, replace = FALSE)
  datos_20[na_positions, col] <- NA  
}

for (col in colnames(datos_50)) {
  cant_missings <- round(nrow(datos_50) * 0.5)
  na_positions <- sample(nrow(datos_50), cant_missings, replace = FALSE)
  datos_50[na_positions, col] <- NA  
}

for (col in colnames(datos_75)) {
  cant_missings <- round(nrow(datos_75) * 0.75)
  na_positions <- sample(nrow(datos_75), cant_missings, replace = FALSE)
  datos_75[na_positions, col] <- NA  
}

#print(colSums(is.na(datos_20)))
#print(colSums(is.na(datos_50)))
#print(colSums(is.na(datos_75)))

```

Creamos los conjuntos de train, validation y test para los 3 sets nuevos y hacemos grid search para cada uno
```{r , echo=FALSE}
# Set 20% missings
train_20 <- datos_20[train_idx, ]
valid_20 <- datos_20[valid_idx, ]
test_20 <- datos_20[test_idx, ]

# mejor_arbol_20 <- gridSearch(train_20,valid_20,20,20,8)
# mej_auc_20 = mejor_arbol_20[1]
# mej_maxd_20 = mejor_arbol_20[2]
# mej_mins_20 = mejor_arbol_20[3]
# mej_minb_20 = mejor_arbol_20[4]
```

```{r , echo=FALSE}
# Set 50% missings
train_50 <- datos_50[train_idx, ]
valid_50 <- datos_50[valid_idx, ]
test_50 <- datos_50[test_idx, ]

# mejor_arbol_50 <- gridSearch(train_50,valid_50,20,20,8)
# mej_auc_50 = mejor_arbol_50[0]
# mej_maxd_50 = mejor_arbol_50[1]
# mej_mins_50 = mejor_arbol_50[2]
# mej_minb_50 = mejor_arbol_50[3]
```

```{r , echo=FALSE}
# Set 75% missings
train_75 <- datos_75[train_idx, ]
valid_75 <- datos_75[valid_idx, ]
test_75 <- datos_75[test_idx, ]

# mejor_arbol_75 <- gridSearch(train_75,valid_75,20,20,8)
# mej_auc_75 = mejor_arbol_75[0]
# mej_maxd_75 = mejor_arbol_75[1]
# mej_mins_75 = mejor_arbol_75[2]
# mej_minb_75 = mejor_arbol_75[3]
```

